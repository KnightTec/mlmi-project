# mlmi-project
Self-supervised Multimodal Representation Learning - MLMI SS23

## Papers
https://drive.google.com/drive/folders/1udxSmKlTU1gG0vKMj-kEd91CSBJMI-OF

## ShareLatex
https://sharelatex.tum.de/7138674284xmjqszfcktdq

## Baseline Implementations
### Contrastive Multimodal Representation Learning
- [ImageBind](https://github.com/facebookresearch/ImageBind)
- [CLIP](https://github.com/openai/CLIP)
- [MS-CLIP](https://github.com/Hxyou/MSCLIP)
- [CoDi](https://github.com/microsoft/i-Code/tree/main/i-Code-V3)

### Supervised Brain Imaging SOTA (to compare learned representation quality)
- [RadImageNet](https://github.com/BMEII-AI/RadImageNet)
- [MedMNIST](https://medmnist.com/)
- TODO: segmentation & classification
- TODO: Tumor Detection and Classification
- TODO: Neurodegenerative Disease Diagnosis
- TODO: fMRI to Image

## Brain multimodal datasets
- [iEEG-fMRI](https://www.nature.com/articles/s41597-022-01173-0)
- [fMRI-Image](http://naturalscenesdataset.org/)
- [MRI-CT-PET](http://www.oasis-brains.org/)
- [MRI-PET_DTI](https://tadpole.grand-challenge.org/Data/)
- TODO: https://github.com/sfikas/medical-imaging-datasets

### Medical multimodal reviews
- [Review 2022](https://drive.google.com/file/d/1Bm9KTSyNnRDZkC6DUCkqacq80k18Jk4X/view?usp=drive_link)
- [Review 2023](https://www.nature.com/articles/s41746-023-00811-0)
