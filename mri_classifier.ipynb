{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load MIRIAD Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtransforms\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmiriad\u001b[39;00m \u001b[39mimport\u001b[39;00m MiriadDataset\n\u001b[1;32m      5\u001b[0m transform \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose(\n\u001b[1;32m      6\u001b[0m     [transforms\u001b[39m.\u001b[39mToTensor(),\n\u001b[1;32m      7\u001b[0m      transforms\u001b[39m.\u001b[39mNormalize((\u001b[39m0.5\u001b[39m,), (\u001b[39m0.5\u001b[39m,))]\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m batch_size\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))]\n",
    ")\n",
    "\n",
    "batch_size=2\n",
    "\n",
    "train_dataset = MiriadDataset(root=\"data/miriad\", train=True, transform=transform, crop=0.7)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "val_dataset = MiriadDataset(root=\"data/miriad\", train=False, transform=transform, crop=0.7)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('HC', 'AD')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "mris, labels = next(dataiter)\n",
    "\n",
    "print(mris.size())\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "i = 0\n",
    "for sample_data, sample_label in zip(mris, labels):\n",
    "    mri_sample_slice = sample_data[0, 16, :, :]\n",
    "    plt.subplot(1, batch_size, i+1)  # Create a subplot for each sample\n",
    "    plt.imshow(mri_sample_slice.T, cmap='gray', origin='lower')\n",
    "    plt.title(f\"{classes[sample_label]}\")  # Display the label as the title\n",
    "    i += 1\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 3D-CNN Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlzheimersClassification3DCNN(\n",
      "  (_conv_layers): Sequential(\n",
      "    (0): Conv3d(1, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): Conv3d(8, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): AdaptiveAvgPool3d(output_size=(4, 4, 4))\n",
      "  )\n",
      "  (_fc1): Linear(in_features=1024, out_features=256, bias=True)\n",
      "  (_dropout): Dropout(p=0.2, inplace=False)\n",
      "  (_fc2): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "Parameter count = 268153\n"
     ]
    }
   ],
   "source": [
    "from models import AlzheimersClassification3DCNN\n",
    "\n",
    "model = AlzheimersClassification3DCNN().double().to(device)\n",
    "print(model)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Parameter count = {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Epoch 1 of 25\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e30327b01794a159f5d524f79f459a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m     15\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[INFO]: Epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m of \u001b[39m\u001b[39m{\u001b[39;00mepochs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m     train_epoch_loss, train_epoch_acc \u001b[39m=\u001b[39m train(model, train_loader, \n\u001b[1;32m     17\u001b[0m                                             optimizer, criterion, device)\n\u001b[1;32m     18\u001b[0m     valid_epoch_loss, valid_epoch_acc \u001b[39m=\u001b[39m validate(model, val_loader,  \n\u001b[1;32m     19\u001b[0m                                                 criterion, device)\n\u001b[1;32m     20\u001b[0m     writer\u001b[39m.\u001b[39madd_scalars(\u001b[39m\"\u001b[39m\u001b[39mLoss\u001b[39m\u001b[39m\"\u001b[39m, {\u001b[39m\"\u001b[39m\u001b[39mTraining\u001b[39m\u001b[39m\"\u001b[39m : \u001b[39mfloat\u001b[39m(train_epoch_loss), \u001b[39m\"\u001b[39m\u001b[39mValidation\u001b[39m\u001b[39m\"\u001b[39m: valid_epoch_loss}, epoch)\n",
      "File \u001b[0;32m~/workspace/mlmi-project/training.py:21\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, trainloader, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m     19\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     20\u001b[0m \u001b[39m# forward pass\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m outputs \u001b[39m=\u001b[39m model(image)\n\u001b[1;32m     22\u001b[0m \u001b[39m# calculate the loss\u001b[39;00m\n\u001b[1;32m     23\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlmi/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/workspace/mlmi-project/models.py:36\u001b[0m, in \u001b[0;36mAlzheimersClassification3DCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 36\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_layers(x)\n\u001b[1;32m     37\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x, \u001b[39m1\u001b[39m) \u001b[39m# flatten all dimensions except batch\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fc1(x))\n",
      "File \u001b[0;32m~/miniconda3/envs/mlmi/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/mlmi/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/mlmi/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/mlmi/lib/python3.11/site-packages/torch/nn/modules/conv.py:613\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 613\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlmi/lib/python3.11/site-packages/torch/nn/modules/conv.py:608\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    597\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv3d(\n\u001b[1;32m    598\u001b[0m         F\u001b[39m.\u001b[39mpad(\n\u001b[1;32m    599\u001b[0m             \u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups,\n\u001b[1;32m    607\u001b[0m     )\n\u001b[0;32m--> 608\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv3d(\n\u001b[1;32m    609\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups\n\u001b[1;32m    610\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from training import train, validate\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# training \n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0002, momentum=0.9, weight_decay=0.001)\n",
    "epochs = 25\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"[INFO]: Epoch {epoch+1} of {epochs}\")\n",
    "    train_epoch_loss, train_epoch_acc = train(model, train_loader, \n",
    "                                            optimizer, criterion, device)\n",
    "    valid_epoch_loss, valid_epoch_acc = validate(model, val_loader,  \n",
    "                                                criterion, device)\n",
    "    writer.add_scalars(\"Loss\", {\"Training\" : float(train_epoch_loss), \"Validation\": valid_epoch_loss}, epoch)\n",
    "    writer.add_scalars(\"Accuracy\", {\"Training\" : train_epoch_acc, \"Validation\": valid_epoch_acc}, epoch)\n",
    "    print(f\"Training loss: {train_epoch_loss:.3f}, training acc: {train_epoch_acc:.3f}\")\n",
    "    print(f\"Validation loss: {valid_epoch_loss:.3f}, validation acc: {valid_epoch_acc:.3f}\")\n",
    "\n",
    "writer.flush()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Swin-Transformer Classification Model (scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SvinViTAlzheimersClassifier(\n",
      "  (_svin_vit): SwinTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv3d(1, 48, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "    (layers1): ModuleList(\n",
      "      (0): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0-1): 2 x SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=48, out_features=144, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=48, out_features=48, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "            (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): MLPBlock(\n",
      "              (linear1): Linear(in_features=48, out_features=192, bias=True)\n",
      "              (linear2): Linear(in_features=192, out_features=48, bias=True)\n",
      "              (fn): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchMerging(\n",
      "          (reduction): Linear(in_features=384, out_features=96, bias=False)\n",
      "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layers2): ModuleList(\n",
      "      (0): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0-1): 2 x SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): MLPBlock(\n",
      "              (linear1): Linear(in_features=96, out_features=384, bias=True)\n",
      "              (linear2): Linear(in_features=384, out_features=96, bias=True)\n",
      "              (fn): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchMerging(\n",
      "          (reduction): Linear(in_features=768, out_features=192, bias=False)\n",
      "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layers3): ModuleList(\n",
      "      (0): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0-1): 2 x SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): MLPBlock(\n",
      "              (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (fn): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchMerging(\n",
      "          (reduction): Linear(in_features=1536, out_features=384, bias=False)\n",
      "          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layers4): ModuleList(\n",
      "      (0): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0-1): 2 x SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): MLPBlock(\n",
      "              (linear1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (linear2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (fn): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchMerging(\n",
      "          (reduction): Linear(in_features=3072, out_features=768, bias=False)\n",
      "          (norm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_global_avg_pool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
      "  (_fc): Linear(in_features=768, out_features=1, bias=True)\n",
      ")\n",
      "Parameter count = 8062771\n"
     ]
    }
   ],
   "source": [
    "from models import SvinViTAlzheimersClassifier\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "swin_model = SvinViTAlzheimersClassifier().double().to(device)\n",
    "print(swin_model)\n",
    "total_params = sum(p.numel() for p in swin_model.parameters())\n",
    "print(f\"Parameter count = {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Epoch 1 of 25\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48f9c382b8594989bc377a7b4dfe354c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfcedb58e8c14d5ca16ce4f4b80b4e4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.793, training acc: 52.500\n",
      "Validation loss: 0.766, validation acc: 58.750\n",
      "[INFO]: Epoch 2 of 25\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26026882177249a584bbbe4ff93cd805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b48ba460414281840835c359a51634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.738, training acc: 48.125\n",
      "Validation loss: 0.775, validation acc: 41.250\n",
      "[INFO]: Epoch 3 of 25\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e453806f5b44d4c90d49d60299f87fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abc3bbb09fdf4807a7f679592f506984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.713, training acc: 50.000\n",
      "Validation loss: 0.686, validation acc: 58.750\n",
      "[INFO]: Epoch 4 of 25\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c23d8555d542a8a6c75827645342e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8658cc5a5c284b71a1db5d7769aaab9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.712, training acc: 50.625\n",
      "Validation loss: 0.746, validation acc: 41.250\n",
      "[INFO]: Epoch 5 of 25\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6476a64610c64234aa67be8dfee392dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46d1bc98da54e83b5a39b645299fd80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.714, training acc: 48.125\n",
      "Validation loss: 0.678, validation acc: 41.250\n",
      "[INFO]: Epoch 6 of 25\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "394b8be05236453ba73f1a9821cb78bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5aaa389341e4bc49f248e74e90500c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.694, training acc: 53.125\n",
      "Validation loss: 0.819, validation acc: 58.750\n",
      "[INFO]: Epoch 7 of 25\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "120ffe064d324b859c2d8b2ad05fb48c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d3ce67a61fa430c911af3972dcdbed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.726, training acc: 51.250\n",
      "Validation loss: 0.794, validation acc: 41.250\n",
      "[INFO]: Epoch 8 of 25\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb82d1967c7a41d2a9d2681cc38093f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11bcb0bc77184743a42890632b94bd65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.702, training acc: 50.000\n",
      "Validation loss: 0.678, validation acc: 41.250\n",
      "[INFO]: Epoch 9 of 25\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f418413e50e4b89bf4b60cf168c52ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0ec26ba0af49e09df0b02d6c27193b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.707, training acc: 50.000\n",
      "Validation loss: 0.684, validation acc: 41.250\n",
      "[INFO]: Epoch 10 of 25\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5a9a49116444ecfa6f4ab2d2db21a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0429075f3b4aea86fc6bcf33f74e15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.706, training acc: 49.375\n",
      "Validation loss: 0.682, validation acc: 58.750\n",
      "[INFO]: Epoch 11 of 25\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d5f9065a574d3e9fea7dd4ab0f5f0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb02b92e5e314a968dce8b4f72b5d7f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.714, training acc: 48.125\n",
      "Validation loss: 0.705, validation acc: 41.250\n",
      "[INFO]: Epoch 12 of 25\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d576a6958a0c4fc9a160227d5c491fd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f470d98a48ee48139b1f065966856076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.700, training acc: 50.625\n",
      "Validation loss: 0.678, validation acc: 41.250\n",
      "[INFO]: Epoch 13 of 25\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc30e696acd4908b9c1fa09ba521d8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42fbde5f03f34affa2873c652a32a8a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.699, training acc: 54.375\n",
      "Validation loss: 0.763, validation acc: 41.250\n",
      "[INFO]: Epoch 14 of 25\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a0facb95f46466c92cb10947975fafe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49b581c75fa443eaa3c648a55f8904e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.703, training acc: 50.000\n",
      "Validation loss: 0.680, validation acc: 41.250\n",
      "[INFO]: Epoch 15 of 25\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ff8ee29dd149e5bbe34818d0007a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01b83821f8024699a03e030d6f55e067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.696, training acc: 50.000\n",
      "Validation loss: 0.681, validation acc: 41.250\n",
      "[INFO]: Epoch 16 of 25\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ba38255be04e41936b64a039d1ae43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7308a4e5286c41ec86158d78af473423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.699, training acc: 50.000\n",
      "Validation loss: 0.687, validation acc: 41.250\n",
      "[INFO]: Epoch 17 of 25\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2076fe0688ea498c8ebe45f9ac6a708d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27acfb7b72184d9baf2131f0ae22f7e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.710, training acc: 50.000\n",
      "Validation loss: 0.678, validation acc: 41.250\n",
      "[INFO]: Epoch 18 of 25\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "110f928b66024c31b772dc214d34936f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7f3a6b4dada4b5186da62c70088456f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.699, training acc: 52.500\n",
      "Validation loss: 0.713, validation acc: 41.250\n",
      "[INFO]: Epoch 19 of 25\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8e598d963c4d14a41f576e9c48976c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1450d6743d2f4d06b0b6896ad8c50054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.707, training acc: 50.000\n",
      "Validation loss: 0.710, validation acc: 41.250\n",
      "[INFO]: Epoch 20 of 25\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cb5b2a3608f4295a722b5156558ab0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab6e37477c8b445f8534ca79fea3e4dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.702, training acc: 50.000\n",
      "Validation loss: 0.721, validation acc: 41.250\n",
      "[INFO]: Epoch 21 of 25\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99a914aefa444cd9e3967d9d03dd39c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d128eaff2ca4ef59a7c8421152e2d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.700, training acc: 50.000\n",
      "Validation loss: 0.688, validation acc: 41.250\n",
      "[INFO]: Epoch 22 of 25\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b41ff35d92d245c49aab24df9090566a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f14859ac69394cf1bd004f85af16d158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.699, training acc: 50.000\n",
      "Validation loss: 0.680, validation acc: 41.250\n",
      "[INFO]: Epoch 23 of 25\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88dc43f6bdef4e889c44f7a31c6dda5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df836cee235b47a6903daa60f31e3a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.700, training acc: 50.000\n",
      "Validation loss: 0.688, validation acc: 41.250\n",
      "[INFO]: Epoch 24 of 25\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80bc954b0c9d48b390115659212b9643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a540be76a05645079d3a85e3e1b07c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.702, training acc: 50.000\n",
      "Validation loss: 0.697, validation acc: 41.250\n",
      "[INFO]: Epoch 25 of 25\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "309de978574d4f94a7b0359194fc86b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c44e563eba94c2db7766e72f3ab22da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.698, training acc: 50.000\n",
      "Validation loss: 0.698, validation acc: 41.250\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from training import train, validate\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# training \n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(swin_model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "epochs = 25\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"[INFO]: Epoch {epoch+1} of {epochs}\")\n",
    "    train_epoch_loss, train_epoch_acc = train(swin_model, train_loader, \n",
    "                                            optimizer, criterion, device)\n",
    "    valid_epoch_loss, valid_epoch_acc = validate(swin_model, val_loader,  \n",
    "                                                criterion, device)\n",
    "    writer.add_scalars(\"Loss\", {\"Training\" : float(train_epoch_loss), \"Validation\": valid_epoch_loss}, epoch)\n",
    "    writer.add_scalars(\"Accuracy\", {\"Training\" : train_epoch_acc, \"Validation\": valid_epoch_acc}, epoch)\n",
    "    print(f\"Training loss: {train_epoch_loss:.3f}, training acc: {train_epoch_acc:.3f}\")\n",
    "    print(f\"Validation loss: {valid_epoch_loss:.3f}, validation acc: {valid_epoch_acc:.3f}\")\n",
    "\n",
    "writer.flush()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Swin-Transformer Classification Small Model (scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SvinViTAlzheimersClassifierSmall(\n",
      "  (_svin_vit): SwinTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv3d(1, 8, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "    (layers1): ModuleList(\n",
      "      (0): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0-1): 2 x SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=8, out_features=24, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=8, out_features=8, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "            (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): MLPBlock(\n",
      "              (linear1): Linear(in_features=8, out_features=16, bias=True)\n",
      "              (linear2): Linear(in_features=16, out_features=8, bias=True)\n",
      "              (fn): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchMerging(\n",
      "          (reduction): Linear(in_features=64, out_features=16, bias=False)\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layers2): ModuleList(\n",
      "      (0): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0-1): 2 x SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=16, out_features=48, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=16, out_features=16, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "            (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): MLPBlock(\n",
      "              (linear1): Linear(in_features=16, out_features=32, bias=True)\n",
      "              (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
      "              (fn): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchMerging(\n",
      "          (reduction): Linear(in_features=128, out_features=32, bias=False)\n",
      "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layers3): ModuleList(\n",
      "      (0): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0-1): 2 x SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=32, out_features=96, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "            (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): MLPBlock(\n",
      "              (linear1): Linear(in_features=32, out_features=64, bias=True)\n",
      "              (linear2): Linear(in_features=64, out_features=32, bias=True)\n",
      "              (fn): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchMerging(\n",
      "          (reduction): Linear(in_features=256, out_features=64, bias=False)\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layers4): ModuleList(\n",
      "      (0): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0-1): 2 x SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=64, out_features=192, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): MLPBlock(\n",
      "              (linear1): Linear(in_features=64, out_features=128, bias=True)\n",
      "              (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "              (fn): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchMerging(\n",
      "          (reduction): Linear(in_features=512, out_features=128, bias=False)\n",
      "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_global_avg_pool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
      "  (_fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Parameter count = 222581\n"
     ]
    }
   ],
   "source": [
    "from models import SvinViTAlzheimersClassifierSmall\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "swin_model_small = SvinViTAlzheimersClassifierSmall().double().to(device)\n",
    "print(swin_model_small)\n",
    "total_params = sum(p.numel() for p in swin_model_small.parameters())\n",
    "print(f\"Parameter count = {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Epoch 1 of 30\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70485b1bbce341b9af8aed975d6b559f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 1.\nOriginal Traceback (most recent call last):\n  File \"/home/sven/miniconda3/envs/mlmi/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/sven/miniconda3/envs/mlmi/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/sven/miniconda3/envs/mlmi/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py\", line 265, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/sven/miniconda3/envs/mlmi/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py\", line 142, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/sven/miniconda3/envs/mlmi/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py\", line 142, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/sven/miniconda3/envs/mlmi/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py\", line 119, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/sven/miniconda3/envs/mlmi/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py\", line 162, in collate_tensor_fn\n    return torch.stack(batch, 0, out=out)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: stack expects each tensor to be equal size, but got [1, 36, 77, 77] at entry 0 and [1, 37, 77, 77] at entry 1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m     17\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[INFO]: Epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m of \u001b[39m\u001b[39m{\u001b[39;00mepochs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m     train_epoch_loss, train_epoch_acc \u001b[39m=\u001b[39m train(swin_model_small, train_loader, \n\u001b[1;32m     19\u001b[0m                                             optimizer, criterion, device)\n\u001b[1;32m     20\u001b[0m     valid_epoch_loss, valid_epoch_acc \u001b[39m=\u001b[39m validate(swin_model_small, val_loader,  \n\u001b[1;32m     21\u001b[0m                                                 criterion, device)\n\u001b[1;32m     22\u001b[0m     writer\u001b[39m.\u001b[39madd_scalars(\u001b[39m\"\u001b[39m\u001b[39mLoss\u001b[39m\u001b[39m\"\u001b[39m, {\u001b[39m\"\u001b[39m\u001b[39mTraining\u001b[39m\u001b[39m\"\u001b[39m : \u001b[39mfloat\u001b[39m(train_epoch_loss), \u001b[39m\"\u001b[39m\u001b[39mValidation\u001b[39m\u001b[39m\"\u001b[39m: valid_epoch_loss}, epoch)\n",
      "File \u001b[0;32m~/workspace/mlmi-project/training.py:11\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, trainloader, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m      9\u001b[0m train_running_correct \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     10\u001b[0m counter \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> 11\u001b[0m \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39m(trainloader), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(trainloader)):\n\u001b[1;32m     12\u001b[0m     counter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     13\u001b[0m     image, labels \u001b[39m=\u001b[39m data\n",
      "File \u001b[0;32m~/miniconda3/envs/mlmi/lib/python3.11/site-packages/tqdm/notebook.py:254\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     it \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m(tqdm_notebook, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__iter__\u001b[39m()\n\u001b[0;32m--> 254\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m it:\n\u001b[1;32m    255\u001b[0m         \u001b[39m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    256\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m    257\u001b[0m \u001b[39m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mlmi/lib/python3.11/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mlmi/lib/python3.11/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/mlmi/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1325\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1323\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rcvd_idx]) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m   1324\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info\u001b[39m.\u001b[39mpop(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rcvd_idx)[\u001b[39m1\u001b[39m]\n\u001b[0;32m-> 1325\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m   1328\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_data()\n",
      "File \u001b[0;32m~/miniconda3/envs/mlmi/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[1;32m   1370\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1371\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m   1372\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/mlmi/lib/python3.11/site-packages/torch/_utils.py:644\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    642\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    643\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 644\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 1.\nOriginal Traceback (most recent call last):\n  File \"/home/sven/miniconda3/envs/mlmi/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/sven/miniconda3/envs/mlmi/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/sven/miniconda3/envs/mlmi/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py\", line 265, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/sven/miniconda3/envs/mlmi/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py\", line 142, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/sven/miniconda3/envs/mlmi/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py\", line 142, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/sven/miniconda3/envs/mlmi/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py\", line 119, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/sven/miniconda3/envs/mlmi/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py\", line 162, in collate_tensor_fn\n    return torch.stack(batch, 0, out=out)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: stack expects each tensor to be equal size, but got [1, 36, 77, 77] at entry 0 and [1, 37, 77, 77] at entry 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from training import train, validate\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# training \n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(swin_model_small.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "epochs = 30\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"[INFO]: Epoch {epoch+1} of {epochs}\")\n",
    "    train_epoch_loss, train_epoch_acc = train(swin_model_small, train_loader, \n",
    "                                            optimizer, criterion, device)\n",
    "    valid_epoch_loss, valid_epoch_acc = validate(swin_model_small, val_loader,  \n",
    "                                                criterion, device)\n",
    "    writer.add_scalars(\"Loss\", {\"Training\" : float(train_epoch_loss), \"Validation\": valid_epoch_loss}, epoch)\n",
    "    writer.add_scalars(\"Accuracy\", {\"Training\" : train_epoch_acc, \"Validation\": valid_epoch_acc}, epoch)\n",
    "    print(f\"Training loss: {train_epoch_loss:.3f}, training acc: {train_epoch_acc:.3f}\")\n",
    "    print(f\"Validation loss: {valid_epoch_loss:.3f}, validation acc: {valid_epoch_acc:.3f}\")\n",
    "\n",
    "writer.flush()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Swin-Transformer Classification Large Model (pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinVitPretrainedClassifier(\n",
      "  (_conv): Conv3d(1, 4, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  (swinViT): SwinTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv3d(4, 48, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "    (layers1): ModuleList(\n",
      "      (0): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0-1): 2 x SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=48, out_features=144, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=48, out_features=48, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "            (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): MLPBlock(\n",
      "              (linear1): Linear(in_features=48, out_features=192, bias=True)\n",
      "              (linear2): Linear(in_features=192, out_features=48, bias=True)\n",
      "              (fn): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchMerging(\n",
      "          (reduction): Linear(in_features=384, out_features=96, bias=False)\n",
      "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layers2): ModuleList(\n",
      "      (0): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0-1): 2 x SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): MLPBlock(\n",
      "              (linear1): Linear(in_features=96, out_features=384, bias=True)\n",
      "              (linear2): Linear(in_features=384, out_features=96, bias=True)\n",
      "              (fn): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchMerging(\n",
      "          (reduction): Linear(in_features=768, out_features=192, bias=False)\n",
      "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layers3): ModuleList(\n",
      "      (0): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0-1): 2 x SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): MLPBlock(\n",
      "              (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (fn): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchMerging(\n",
      "          (reduction): Linear(in_features=1536, out_features=384, bias=False)\n",
      "          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layers4): ModuleList(\n",
      "      (0): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0-1): 2 x SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): MLPBlock(\n",
      "              (linear1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (linear2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (fn): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchMerging(\n",
      "          (reduction): Linear(in_features=3072, out_features=768, bias=False)\n",
      "          (norm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_global_avg_pool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
      "  (_fc0): Linear(in_features=768, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from models import SwinVitPretrainedClassifier\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "pretrained_swin_weights_path = \"pretrained/fold4_f48_ep300_4gpu_dice0_9035/model.pt\"\n",
    "pretrained_weights = torch.load(pretrained_swin_weights_path)\n",
    "\n",
    "state_dict_mod = {}\n",
    "for key, value in pretrained_weights[\"state_dict\"].items():\n",
    "    # some modification to be able to load the params correctly\n",
    "    parts = key.split('.')\n",
    "    parts[0] = 'module'\n",
    "    new_key = '.'.join(parts)\n",
    "    new_key = new_key.replace(\"linear\", \"fc\" )\n",
    "    state_dict_mod[new_key] = value\n",
    "\n",
    "pretrained_weights[\"state_dict\"] = state_dict_mod\n",
    "\n",
    "swin_pretrained_model = SwinVitPretrainedClassifier().double().to(device)\n",
    "swin_pretrained_model.load_from(pretrained_weights)\n",
    "print(swin_pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Epoch 1 of 10\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c228bbf8c1ab4a5c869e037e0ca29c03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6909d4d0b23f40f3942f096e9f979b15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.707, training acc: 50.625\n",
      "Validation loss: 0.693, validation acc: 52.500\n",
      "[INFO]: Epoch 2 of 10\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61f640fbd47b4012b67eef1add8aed39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5fbb2b53aea464ea97907ca6ddf1cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.703, training acc: 50.625\n",
      "Validation loss: 0.712, validation acc: 52.500\n",
      "[INFO]: Epoch 3 of 10\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1727d166a12745c8bcee053d425a164d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d696a7cd89a84006bbd578ae0fc96320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.704, training acc: 48.750\n",
      "Validation loss: 0.692, validation acc: 52.500\n",
      "[INFO]: Epoch 4 of 10\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "555f3163dcd54a1db5765549b0b65b99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e6d3b98b3e40578bd8da7efc4e1309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.701, training acc: 50.625\n",
      "Validation loss: 0.707, validation acc: 52.500\n",
      "[INFO]: Epoch 5 of 10\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "624fe3811a1c45ee8d8a913b5747ca1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c798a76212a64069976de9459ad8d38b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.702, training acc: 50.625\n",
      "Validation loss: 0.718, validation acc: 52.500\n",
      "[INFO]: Epoch 6 of 10\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2b278bac4514390b402847d94e5e8d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba502fbcbf64a26a1a596687daf8c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.695, training acc: 49.375\n",
      "Validation loss: 0.694, validation acc: 52.500\n",
      "[INFO]: Epoch 7 of 10\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b688bb7d9f364603aacdf2a10603fd44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38592276419246f79251bcb0a80dfb3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.702, training acc: 50.625\n",
      "Validation loss: 0.696, validation acc: 52.500\n",
      "[INFO]: Epoch 8 of 10\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a7f105cf41c452fa8c785def7e1d56f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e291dff805840b790ea1049050b840d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.707, training acc: 50.625\n",
      "Validation loss: 0.692, validation acc: 52.500\n",
      "[INFO]: Epoch 9 of 10\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea31df69e24479d9d43c1cdcd3a46a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b563147fac4baa999e9267655d1067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.708, training acc: 50.625\n",
      "Validation loss: 0.692, validation acc: 52.500\n",
      "[INFO]: Epoch 10 of 10\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261258a434284cdf800b0367a3627add",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb251c85dd994ab3b12a9f76ca6cf031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.689, training acc: 51.250\n",
      "Validation loss: 0.750, validation acc: 47.500\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from training import train, validate\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# training \n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.cuda.empty_cache() \n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(swin_pretrained_model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"[INFO]: Epoch {epoch+1} of {epochs}\")\n",
    "    train_epoch_loss, train_epoch_acc = train(swin_pretrained_model, train_loader, \n",
    "                                            optimizer, criterion, device)\n",
    "    valid_epoch_loss, valid_epoch_acc = validate(swin_pretrained_model, val_loader,  \n",
    "                                                criterion, device)\n",
    "    writer.add_scalars(\"Loss\", {\"Training\" : float(train_epoch_loss), \"Validation\": valid_epoch_loss}, epoch)\n",
    "    writer.add_scalars(\"Accuracy\", {\"Training\" : train_epoch_acc, \"Validation\": valid_epoch_acc}, epoch)\n",
    "    print(f\"Training loss: {train_epoch_loss:.3f}, training acc: {train_epoch_acc:.3f}\")\n",
    "    print(f\"Validation loss: {valid_epoch_loss:.3f}, validation acc: {valid_epoch_acc:.3f}\")\n",
    "\n",
    "writer.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ('mlmi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25a19fbe0a9132dfb9279d48d161753c6352f8f9478c2e74383d340069b907c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
