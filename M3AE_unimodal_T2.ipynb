{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyOmwW+8idIg4jUjW8HeE0oV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MocBlV5l-Gqy","executionInfo":{"status":"ok","timestamp":1694953741111,"user_tz":-120,"elapsed":22131,"user":{"displayName":"P.R. Huang","userId":"02961530315239686171"}},"outputId":"2042a0df-f25f-4a17-c245-524e5798b53b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install monai\n","!pip install torchmetrics==0.7.2\n","!pip install transformers\n","!pip install einops\n","!pip install timm==0.4.12"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e9k2wPIFqFdd","executionInfo":{"status":"ok","timestamp":1694953789407,"user_tz":-120,"elapsed":32028,"user":{"displayName":"P.R. Huang","userId":"02961530315239686171"}},"outputId":"d2c83f73-831d-4898-88d7-d07dd4600ece"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting monai\n","  Downloading monai-1.2.0-202306081546-py3-none-any.whl (1.3 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.3 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from monai) (2.0.1+cu118)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from monai) (1.23.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9->monai) (3.27.4.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9->monai) (16.0.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->monai) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9->monai) (1.3.0)\n","Installing collected packages: monai\n","Successfully installed monai-1.2.0\n","Collecting torchmetrics==0.7.2\n","  Downloading torchmetrics-0.7.2-py3-none-any.whl (397 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.2/397.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from torchmetrics==0.7.2) (1.23.5)\n","Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics==0.7.2) (2.0.1+cu118)\n","Collecting pyDeprecate==0.3.* (from torchmetrics==0.7.2)\n","  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchmetrics==0.7.2) (23.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.1->torchmetrics==0.7.2) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.1->torchmetrics==0.7.2) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.1->torchmetrics==0.7.2) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.1->torchmetrics==0.7.2) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.1->torchmetrics==0.7.2) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.1->torchmetrics==0.7.2) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3.1->torchmetrics==0.7.2) (3.27.4.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3.1->torchmetrics==0.7.2) (16.0.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3.1->torchmetrics==0.7.2) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3.1->torchmetrics==0.7.2) (1.3.0)\n","Installing collected packages: pyDeprecate, torchmetrics\n","Successfully installed pyDeprecate-0.3.2 torchmetrics-0.7.2\n","Collecting transformers\n","  Downloading transformers-4.33.2-py3-none-any.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n","  Downloading huggingface_hub-0.17.1-py3-none-any.whl (294 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.8/294.8 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m110.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.17.1 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.33.2\n","Collecting einops\n","  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: einops\n","Successfully installed einops-0.6.1\n","Collecting timm==0.4.12\n","  Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.0/377.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.10/dist-packages (from timm==0.4.12) (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm==0.4.12) (0.15.2+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.12) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.12) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.12) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.12) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.12) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.12) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4->timm==0.4.12) (3.27.4.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4->timm==0.4.12) (16.0.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.4.12) (1.23.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.4.12) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.4.12) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4->timm==0.4.12) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->timm==0.4.12) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->timm==0.4.12) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->timm==0.4.12) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->timm==0.4.12) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4->timm==0.4.12) (1.3.0)\n","Installing collected packages: timm\n","Successfully installed timm-0.4.12\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"YLT8hh9205oT"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"030bc28d","executionInfo":{"status":"ok","timestamp":1694953805047,"user_tz":-120,"elapsed":10820,"user":{"displayName":"P.R. Huang","userId":"02961530315239686171"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import torch.backends.cudnn as cudnn\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy\n","import random\n","import py\n","from sklearn.metrics import classification_report\n","from monai.data import decollate_batch, DataLoader, CacheDataset, ThreadDataLoader\n","from monai.metrics import ROCAUCMetric\n","from monai.transforms import (\n","    Activations,\n","    EnsureChannelFirstd,\n","    Compose,\n","    LoadImaged,\n","    ScaleIntensityd,\n","    EnsureTyped,\n","    Resized,\n","    CropForegroundd,\n","    SpatialPadd,\n","    CastToTyped,\n",")\n","from monai.utils import set_determinism\n"]},{"cell_type":"code","source":["import sys\n","import os\n","import requests\n","\n","import torch\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","\n","# check whether run in Colab\n","if 'google.colab' in sys.modules:\n","    print('Running in Colab.')\n","    !pip3 install timm==0.4.5  # 0.3.2 does not work in Colab\n","    !git clone https://github.com/facebookresearch/mae.git\n","    sys.path.append('./mae')\n","else:\n","    sys.path.append('..')\n","import models_mae"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dxUEbs-O0978","executionInfo":{"status":"ok","timestamp":1694953814356,"user_tz":-120,"elapsed":6817,"user":{"displayName":"P.R. Huang","userId":"02961530315239686171"}},"outputId":"bdf3bf07-9078-4e80-9fb8-bcb02a8d45b8"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Running in Colab.\n","Collecting timm==0.4.5\n","  Downloading timm-0.4.5-py3-none-any.whl (287 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.4/287.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.10/dist-packages (from timm==0.4.5) (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm==0.4.5) (0.15.2+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.5) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.5) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.5) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.5) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.5) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.5) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4->timm==0.4.5) (3.27.4.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4->timm==0.4.5) (16.0.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.4.5) (1.23.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.4.5) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.4.5) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4->timm==0.4.5) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->timm==0.4.5) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->timm==0.4.5) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->timm==0.4.5) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->timm==0.4.5) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4->timm==0.4.5) (1.3.0)\n","Installing collected packages: timm\n","  Attempting uninstall: timm\n","    Found existing installation: timm 0.4.12\n","    Uninstalling timm-0.4.12:\n","      Successfully uninstalled timm-0.4.12\n","Successfully installed timm-0.4.5\n","Cloning into 'mae'...\n","remote: Enumerating objects: 39, done.\u001b[K\n","remote: Total 39 (delta 0), reused 0 (delta 0), pack-reused 39\u001b[K\n","Receiving objects: 100% (39/39), 829.54 KiB | 24.40 MiB/s, done.\n","Resolving deltas: 100% (12/12), done.\n"]}]},{"cell_type":"code","source":["imagenet_mean = np.array([0.485, 0.456, 0.406])\n","imagenet_std = np.array([0.229, 0.224, 0.225])\n","\n","def show_image(image, title=''):\n","    # image is [H, W, 3]\n","    assert image.shape[2] == 3\n","    plt.imshow(torch.clip((image * imagenet_std + imagenet_mean) * 255, 0, 255).int())\n","    plt.title(title, fontsize=16)\n","    plt.axis('off')\n","    return\n","\n","def prepare_model(chkpt_dir, arch='mae_vit_large_patch16'):\n","    # build model\n","    model = getattr(models_mae, arch)()\n","    # load model\n","    checkpoint = torch.load(chkpt_dir, map_location='cpu')\n","    msg = model.load_state_dict(checkpoint['model'], strict=False)\n","    print(msg)\n","    return model\n","\n","def run_one_image(img, model):\n","    x = torch.tensor(img)\n","\n","    # make it a batch-like\n","    x = x.unsqueeze(dim=0)\n","    x = torch.einsum('nhwc->nchw', x)\n","\n","    # run MAE\n","    loss, y, mask = model(x.float(), mask_ratio=0.75)\n","    y = model.unpatchify(y)\n","    y = torch.einsum('nchw->nhwc', y).detach().cpu()\n","\n","    # visualize the mask\n","    mask = mask.detach()\n","    mask = mask.unsqueeze(-1).repeat(1, 1, model.patch_embed.patch_size[0]**2 *3)  # (N, H*W, p*p*3)\n","    mask = model.unpatchify(mask)  # 1 is removing, 0 is keeping\n","    mask = torch.einsum('nchw->nhwc', mask).detach().cpu()\n","\n","    x = torch.einsum('nchw->nhwc', x)\n","\n","    # masked image\n","    im_masked = x * (1 - mask)\n","\n","    # MAE reconstruction pasted with visible patches\n","    im_paste = x * (1 - mask) + y * mask\n","\n","    # make the plt figure larger\n","    plt.rcParams['figure.figsize'] = [24, 24]\n","\n","    plt.subplot(1, 4, 1)\n","    show_image(x[0], \"original\")\n","\n","    plt.subplot(1, 4, 2)\n","    show_image(im_masked[0], \"masked\")\n","\n","    plt.subplot(1, 4, 3)\n","    show_image(y[0], \"reconstruction\")\n","\n","    plt.subplot(1, 4, 4)\n","    show_image(im_paste[0], \"reconstruction + visible\")\n","\n","    plt.show()"],"metadata":{"id":"aKyBg6dRReaz","executionInfo":{"status":"ok","timestamp":1694953818179,"user_tz":-120,"elapsed":2,"user":{"displayName":"P.R. Huang","userId":"02961530315239686171"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{"id":"0f799d7c","executionInfo":{"status":"ok","timestamp":1694953823539,"user_tz":-120,"elapsed":2,"user":{"displayName":"P.R. Huang","userId":"02961530315239686171"}}},"outputs":[],"source":["def set_seed(no):\n","    torch.manual_seed(no)\n","    random.seed(no)\n","    np.random.seed(no)\n","    os.environ['PYTHONHASHSEED'] = str()\n","    torch.backends.cudnn.benchmark = False\n","    torch.backends.cudnn.deterministic = True\n","\n","set_seed(100)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"ca3bd0f4","executionInfo":{"status":"ok","timestamp":1694953832671,"user_tz":-120,"elapsed":971,"user":{"displayName":"P.R. Huang","userId":"02961530315239686171"}}},"outputs":[],"source":["import pandas as pd\n","import os\n","from enum import Enum\n","from monai.transforms import Transform\n","\n","class Modality(Enum):\n","    MR_T1 = 1\n","    MR_T2 = 2\n","    MR_T2_STAR = 3\n","    MR_FLAIR = 4\n","    MR_TOF_MRA = 5\n","\n","def create_oasis_3_unimodal_dataset(csv_path: str, dataset_root: str, modality: Modality, transform: Transform, cache_rate: float):\n","    train_df = pd.read_csv(csv_path, sep=\";\")\n","    train_df.fillna('', inplace=True)\n","\n","    column_name = \"\"\n","    if modality == Modality.MR_T1:\n","        column_name = \"MR T1w\"\n","    elif modality == Modality.MR_T2:\n","        column_name = \"MR T2w\"\n","    elif modality == Modality.MR_T2_STAR:\n","        column_name = \"MR T2*\"\n","    elif modality == Modality.MR_FLAIR:\n","        column_name = \"MR FLAIR\"\n","    elif modality == Modality.MR_TOF_MRA:\n","        column_name = \"MR TOF-MRA\"\n","    else:\n","        assert(False)\n","\n","    train_data = []\n","    for index, row in train_df.iterrows():\n","        rel_path = row[column_name]\n","        if not rel_path:\n","            continue\n","        image_path = os.path.join(dataset_root, rel_path)\n","        train_data.append({\"image\": image_path, \"label\" : row[\"label\"]})\n","\n","    return CacheDataset(data=train_data, transform=transform, cache_rate=cache_rate, num_workers=5, copy_cache=False)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"b4ed7022","executionInfo":{"status":"ok","timestamp":1694953835712,"user_tz":-120,"elapsed":2,"user":{"displayName":"P.R. Huang","userId":"02961530315239686171"}}},"outputs":[],"source":["dataset_root = r\"/content/drive/MyDrive/OASIS-3-MR-Sessions-2D\""]},{"cell_type":"code","execution_count":10,"metadata":{"id":"fea2ca0e","outputId":"5acd617f-23e5-46ea-beab-00be42cee819","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694953977838,"user_tz":-120,"elapsed":94127,"user":{"displayName":"P.R. Huang","userId":"02961530315239686171"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Loading dataset: 100%|██████████| 215/215 [01:22<00:00,  2.60it/s]\n","Loading dataset: 100%|██████████| 24/24 [00:10<00:00,  2.32it/s]\n"]}],"source":["resolution = 224\n","cache_rate = 0.1 # might need to change this based on the amount of memory available\n","batch_size = 32\n","modality = Modality.MR_T2\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","foreground_crop_threshold = 0.1\n","# train_table_path = \"csv/oasis/oasis_3_multimodal_train.csv\"\n","train_table_path = r\"/content/drive/MyDrive/MLMI/oasis_3_multimodal_train.csv\"\n","transform = Compose([\n","    LoadImaged(\"image\", image_only=True),\n","    EnsureChannelFirstd(keys=[\"image\", \"label\"], channel_dim=\"no_channel\"),\n","    CastToTyped(\"label\", dtype=np.float64),\n","    ScaleIntensityd(\"image\"),\n","    CropForegroundd(\"image\", source_key=\"image\", select_fn=lambda x: x > foreground_crop_threshold, margin=5),\n","    Resized(keys=[\"image\"], spatial_size=resolution, size_mode=\"longest\"),\n","    SpatialPadd(keys=[\"image\"], spatial_size=(resolution, resolution)),\n","    EnsureTyped(\"image\", device=device),\n","    ]\n",")\n","\n","# TODO: fix the following files\n","# TODO: skip them in the dataset\n","'''\n","torch.Size([96, 96, 26])\n","Error transforming file: /mnt/f/OASIS-3-MR-Sessions-2D/OAS30033_MR_d0133/anat5/NIFTI/sub-OAS30033_ses-d0133_run-02_T2w.nii.gz\n","\n","torch.Size([64, 64, 105])\n","Error transforming file: /mnt/f/OASIS-3-MR-Sessions-2D/OAS31065_MR_d0044/anat7/NIFTI/sub-OAS31065_ses-d0044_echo-1_run-02_FLAIR.nii.gz\n","'''\n","\n","train_ds = create_oasis_3_unimodal_dataset(csv_path=train_table_path, dataset_root=dataset_root, modality=modality, transform=transform, cache_rate=cache_rate)\n","train_loader = ThreadDataLoader(train_ds, num_workers=0, batch_size=batch_size, shuffle=True)\n","\n","# val_table_path = \"csv/oasis/oasis_3_multimodal_val.csv\"\n","val_table_path = r\"/content/drive/MyDrive/MLMI/oasis_3_multimodal_val.csv\"\n","val_ds = create_oasis_3_unimodal_dataset(csv_path=val_table_path, dataset_root=dataset_root, modality=modality, transform=transform, cache_rate=cache_rate)\n","val_loader = ThreadDataLoader(val_ds, num_workers=0, batch_size=batch_size, shuffle=True)\n","\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"f4dce451","executionInfo":{"status":"ok","timestamp":1694953986850,"user_tz":-120,"elapsed":525,"user":{"displayName":"P.R. Huang","userId":"02961530315239686171"}}},"outputs":[],"source":["out_model_dir = r\"/content/drive/MyDrive/M3AE_N/pretrained\"\n","model_file_name = f\"m3ae_unimodal_oasis_3_{str(modality).split('.')[1]}.pth\""]},{"cell_type":"code","source":["# This is an MAE model trained with pixels as targets for visualization (ViT-Large, training mask ratio=0.75)\n","\n","# download checkpoint if not exist\n","!wget -nc https://dl.fbaipublicfiles.com/mae/visualize/mae_visualize_vit_large.pth\n","\n","chkpt_dir = 'mae_visualize_vit_large.pth'\n","model_mae = prepare_model(chkpt_dir, 'mae_vit_large_patch16')\n","print('Model loaded.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2e64U4XQR5Ll","executionInfo":{"status":"ok","timestamp":1694954012264,"user_tz":-120,"elapsed":23016,"user":{"displayName":"P.R. Huang","userId":"02961530315239686171"}},"outputId":"e6d49fe2-c5c4-4a47-90e9-938876ce4d3c"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-09-17 14:33:08--  https://dl.fbaipublicfiles.com/mae/visualize/mae_visualize_vit_large.pth\n","Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 54.192.18.50, 54.192.18.81, 54.192.18.51, ...\n","Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|54.192.18.50|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1318315181 (1.2G) [binary/octet-stream]\n","Saving to: ‘mae_visualize_vit_large.pth’\n","\n","mae_visualize_vit_l 100%[===================>]   1.23G  79.2MB/s    in 17s     \n","\n","2023-09-17 14:33:25 (74.9 MB/s) - ‘mae_visualize_vit_large.pth’ saved [1318315181/1318315181]\n","\n","<All keys matched successfully>\n","Model loaded.\n"]}]},{"cell_type":"code","source":["model_mae"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y3DASqb9XL5t","executionInfo":{"status":"ok","timestamp":1694764393444,"user_tz":-120,"elapsed":692,"user":{"displayName":"P.R. Huang","userId":"02961530315239686171"}},"outputId":"a43fa6d2-3eaa-4f40-d2cf-e04545a4fc1b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MaskedAutoencoderViT(\n","  (patch_embed): PatchEmbed(\n","    (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n","  )\n","  (blocks): ModuleList(\n","    (0-23): 24 x Block(\n","      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): Identity()\n","      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","        (act): GELU(approximate='none')\n","        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","  )\n","  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","  (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)\n","  (decoder_blocks): ModuleList(\n","    (0-7): 8 x Block(\n","      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=512, out_features=512, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): Identity()\n","      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (act): GELU(approximate='none')\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","  )\n","  (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","  (decoder_pred): Linear(in_features=512, out_features=768, bias=True)\n",")"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","execution_count":13,"metadata":{"id":"f8f05003","executionInfo":{"status":"ok","timestamp":1694954019268,"user_tz":-120,"elapsed":5554,"user":{"displayName":"P.R. Huang","userId":"02961530315239686171"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d2e2fe86-0f49-4991-bfaf-5a9c1d5774a8"},"outputs":[{"output_type":"stream","name":"stdout","text":["<All keys matched successfully>\n","Model loaded.\n"]}],"source":["from einops import repeat, rearrange\n","class ViT_Classifier(torch.nn.Module):\n","    def __init__(self, mae, num_classes=1) -> None:\n","        super().__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(1, 3, kernel_size=1, stride=1, padding=0, bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(3)\n","        )\n","        self.mae = mae\n","        self.head = torch.nn.Linear(mae.pos_embed.shape[-1], num_classes)\n","\n","    def forward(self, img):\n","        img = self.conv(img)\n","        features, mask, ids_restore = self.mae.forward_encoder(img, 0)\n","        features = rearrange(features, 'b t c -> t b c')\n","        logits = self.head(features[0])\n","        return logits\n","chkpt_dir = 'mae_visualize_vit_large.pth'\n","model_mae = prepare_model(chkpt_dir, 'mae_vit_large_patch16').cuda()\n","print('Model loaded.')\n","model = ViT_Classifier(model_mae).cuda()\n","# x = torch.ones([2,1,224,224]).cuda()\n","# print(model(x).shape)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"a49230a8","executionInfo":{"status":"ok","timestamp":1694954024138,"user_tz":-120,"elapsed":2,"user":{"displayName":"P.R. Huang","userId":"02961530315239686171"}}},"outputs":[],"source":["model = model.to(device).train()\n","criterion = torch.nn.BCEWithLogitsLoss()\n","scaler = torch.cuda.amp.GradScaler()\n","# optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n","optimizer = optim.Adam(model.parameters(), lr=1e-5)\n","val_interval = 1\n","auc_metric = ROCAUCMetric()"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"c65ac9dd","outputId":"9f5a78de-108d-412c-b1e5-634a93008732","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694958256249,"user_tz":-120,"elapsed":4217982,"user":{"displayName":"P.R. Huang","userId":"02961530315239686171"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["----------\n","epoch 1/10\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 68/68 [56:33<00:00, 49.90s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 1 average loss: 0.4594\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8/8 [06:09<00:00, 46.13s/it]\n"]},{"output_type":"stream","name":"stdout","text":["saved new best metric model\n","current epoch: 1 current AUC: 0.7520 current accuracy: 0.7749 best AUC: 0.7520 at epoch: 1\n","----------\n","epoch 2/10\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 68/68 [00:44<00:00,  1.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 2 average loss: 0.3793\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8/8 [00:04<00:00,  1.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["saved new best metric model\n","current epoch: 2 current AUC: 0.8036 current accuracy: 0.7319 best AUC: 0.8036 at epoch: 2\n","----------\n","epoch 3/10\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 68/68 [00:44<00:00,  1.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 3 average loss: 0.3337\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8/8 [00:04<00:00,  1.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["saved new best metric model\n","current epoch: 3 current AUC: 0.8092 current accuracy: 0.7247 best AUC: 0.8092 at epoch: 3\n","----------\n","epoch 4/10\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 68/68 [00:47<00:00,  1.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 4 average loss: 0.2572\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8/8 [00:04<00:00,  1.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["saved new best metric model\n","current epoch: 4 current AUC: 0.8109 current accuracy: 0.7510 best AUC: 0.8109 at epoch: 4\n","----------\n","epoch 5/10\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 68/68 [00:45<00:00,  1.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 5 average loss: 0.1813\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["current epoch: 5 current AUC: 0.8103 current accuracy: 0.7414 best AUC: 0.8109 at epoch: 4\n","----------\n","epoch 6/10\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 68/68 [00:44<00:00,  1.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 6 average loss: 0.0870\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8/8 [00:04<00:00,  1.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["current epoch: 6 current AUC: 0.7815 current accuracy: 0.7247 best AUC: 0.8109 at epoch: 4\n","----------\n","epoch 7/10\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 68/68 [00:44<00:00,  1.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 7 average loss: 0.0516\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["current epoch: 7 current AUC: 0.7869 current accuracy: 0.7056 best AUC: 0.8109 at epoch: 4\n","----------\n","epoch 8/10\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 68/68 [00:44<00:00,  1.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 8 average loss: 0.0389\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8/8 [00:04<00:00,  1.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["current epoch: 8 current AUC: 0.7838 current accuracy: 0.7056 best AUC: 0.8109 at epoch: 4\n","----------\n","epoch 9/10\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 68/68 [00:44<00:00,  1.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 9 average loss: 0.0172\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n"]},{"output_type":"stream","name":"stdout","text":["current epoch: 9 current AUC: 0.7574 current accuracy: 0.7223 best AUC: 0.8109 at epoch: 4\n","----------\n","epoch 10/10\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 68/68 [00:43<00:00,  1.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 10 average loss: 0.0090\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["current epoch: 10 current AUC: 0.7624 current accuracy: 0.7080 best AUC: 0.8109 at epoch: 4\n","train completed, best_metric (AUC): 0.8109 at epoch: 4\n"]}],"source":["from tqdm import tqdm\n","best_metric = -1\n","best_metric_epoch = -1\n","epoch_loss_values = []\n","metric_values = []\n","\n","y_pred_trans = Compose([Activations(sigmoid=True)])\n","max_epochs = 10\n","for epoch in range(max_epochs):\n","    print(\"-\" * 10)\n","    print(f\"epoch {epoch + 1}/{max_epochs}\")\n","    model.train()\n","    epoch_loss = 0\n","    step = 0\n","    for batch_data in tqdm(train_loader):\n","        step += 1\n","        inputs, labels = batch_data[\"image\"].to(device).float(), batch_data[\"label\"].to(device).float()\n","        optimizer.zero_grad()\n","        with torch.cuda.amp.autocast():\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            # print(outputs)\n","            # print(loss)\n","        # loss.backward()\n","        # optimizer.step()\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        epoch_loss += loss.item()\n","        # print(f\"{step}/{len(train_ds) // train_loader.batch_size}, \" f\"train_loss: {loss.item():.4f}\")\n","        epoch_len = len(train_ds) // train_loader.batch_size\n","    epoch_loss /= step\n","    epoch_loss_values.append(epoch_loss)\n","    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n","\n","    if (epoch + 1) % val_interval == 0:\n","        model.eval()\n","        with torch.no_grad():\n","            y_pred = torch.tensor([], dtype=torch.float32, device=device)\n","            y = torch.tensor([], dtype=torch.long, device=device)\n","            for val_data in tqdm(val_loader):\n","                val_images, val_labels = (\n","                    val_data[\"image\"].to(device),\n","                    val_data[\"label\"].to(device),\n","                )\n","                y_pred = torch.cat([y_pred, model(val_images)], dim=0)\n","                y = torch.cat([y, val_labels], dim=0)\n","            y_onehot = torch.cat([i for i in decollate_batch(y, detach=False)], dim=0)\n","            y_pred_act = torch.cat([y_pred_trans(i) for i in decollate_batch(y_pred)], dim=0)\n","            auc_metric(y_pred_act, y_onehot)\n","            result = auc_metric.aggregate()\n","            auc_metric.reset()\n","            metric_values.append(result)\n","            acc_value = torch.eq((y_pred_act > 0.5).long(), y)\n","            acc_metric = acc_value.float().mean().item()\n","            del y_pred_act, y_onehot\n","            if result > best_metric:\n","                best_metric = result\n","                best_metric_epoch = epoch + 1\n","                torch.save(model.state_dict(), os.path.join(out_model_dir, model_file_name))\n","                print(\"saved new best metric model\")\n","            print(\n","                f\"current epoch: {epoch + 1} current AUC: {result:.4f}\"\n","                f\" current accuracy: {acc_metric:.4f}\"\n","                f\" best AUC: {best_metric:.4f}\"\n","                f\" at epoch: {best_metric_epoch}\"\n","            )\n","\n","print(f\"train completed, best_metric (AUC): {best_metric:.4f} \" f\"at epoch: {best_metric_epoch}\")"]}]}